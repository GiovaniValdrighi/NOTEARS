{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notears_nonlinear.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJyTAu2ZLOAKTm6rx/crC1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovaniValdrighi/NOTEARS/blob/master/notears_nonlinear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUv3o2zBL3av",
        "colab_type": "text"
      },
      "source": [
        "#Notears não-linear\n",
        "Implementação do algoritmo Notears nonlinear para o aprendizado de estruturas (DAG)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQJTo55Xtc5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.optimize as sciops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnCT1iaayAzk",
        "colab_type": "text"
      },
      "source": [
        "https://stackoverflow.com/questions/59029854/use-scipy-optimizer-with-tensorflow-2-0-for-neural-network-training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EZlB8JJ3s2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Notears_MLP(tf.keras.models.Model):\n",
        "  def __init__(self, n_variables, bias = True):\n",
        "    super(Notears_MLP, self).__init__()\n",
        "    self.n_variables = n_variables\n",
        "    self.fc1_pos = tf.keras.layers.Dense(n_variables * n_variables * 2, input_shape = n_variables, use_bias = bias)\n",
        "    self.fc1_neg = tf.keras.layers.Dense(n_variables * n_variables * 2, inout_shape = n_variables, use_bias = bias)\n",
        "    self.fc2 = tf.keras.layers.LocallyConnected1D( kernel_size = 1, input_shape = n_variables * n_variables * 2, use_bias = bias, activation = 'sigmoid')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    hid = self.fc1_pos(inputs) - self.fc1_neg(inputs)\n",
        "    output = self.fc2(hid)\n",
        "    return output\n",
        "\n",
        "  class bound_adj(tf.keras.constraints.Constraint):\n",
        "    def __init__(self):\n",
        "      pass\n",
        "    \n",
        "    def __call__(self, w):\n",
        "      pass\n",
        "\n",
        "  def _h(self):\n",
        "    '''Calculate the constraint of fc1 to ensure that it's a DAG'''\n",
        "    fc1_weights = self.fc1_pos.weights - self.fc1_neg.weights\n",
        "    tf.reshape(fc1_weights, [self.n_variables, self.n_variables])\n",
        "    #preciso transformar na matrix de adjascencia\n",
        "    #(Yu et al. 2019 DAG-GNN)\n",
        "    # h(w) = tr[(I + kA*A)^n_variables] - n_variables\n",
        "    M = tf.eye(n_variables, num_columns = n_variables) + A/n_variables\n",
        "    E = tf.pow(M, n_variables - 1)\n",
        "    h = tf.math.reduce_sum(tf.transpose(E) * M) - n_variables\n",
        "  \n",
        "  def _l2_loss(self):\n",
        "    '''Calculate L2 loss from model parameters'''\n",
        "    loss = 0\n",
        "    fc1_weights = self.fc1_pos.weights - self.fc1_neg.weights\n",
        "    loss +=  tf.math.reduce_sum(tf.pow(fc1_weights, 2))\n",
        "    for layer in self.fc2:\n",
        "      loss += tf.math.reduce_sum(tf.pow(layer.weights, 2))\n",
        "    return loss\n",
        "\n",
        "  def _l1_loss(self):\n",
        "    '''Calculate L1 loss from fc1 parameters'''\n",
        "    return tf.math.reduce_sum(self.fc1_pos.weights + self.fc1_neg.weights)\n",
        "\n",
        "  def to_adj(self):\n",
        "    '''Reshape fc1 to an adjacency matrix'''\n",
        "    fc1_weights = self.fc1_pos.weights - self.fc1_neg.weights\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PHHCqIzxtut",
        "colab_type": "code",
        "outputId": "ae6cd29e-9195-45bc-8e42-182ecd4fae5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "a**2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 1,  4],\n",
              "       [ 9, 16]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIFut10gte6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_iter = 1e16\n",
        "rho = 1e20\n",
        "c = 0.25\n",
        "h_tol = 1e-4\n",
        "\n",
        "rho = 0.\n",
        "alpha = 0.\n",
        "h = np.inf\n",
        "for _ in range(max_iter):\n",
        "  h_new = None\n",
        "  W_new = None\n",
        "  while rho < rho_max:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    h_new = model.h_()\n",
        "    if h_new > c * h:\n",
        "      rho = 10*rho\n",
        "    else:\n",
        "      break\n",
        "  alpha += rho * h_new\n",
        "  if h <= h_tol or rho >= rho_max:\n",
        "    break\n",
        "W_est = model.fc1_to_adj()\n",
        "W_est[np.abs(W_est) < threshold] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}